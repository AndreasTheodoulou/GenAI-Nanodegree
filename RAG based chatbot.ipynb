{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "124e5672",
   "metadata": {},
   "source": [
    "# RAG-based Custom Chatbot Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4a94b3",
   "metadata": {},
   "source": [
    "TODO: In this cell, write an explanation of which dataset you have chosen and why it is appropriate for this task.\n",
    "\n",
    "I choose wikipedia dataset. Even though the dataset has probably been used to train the model, applying RAG on the specific Wikipedia page might allow the model to tackle more narrow questions on the topic, and reduce hallucination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "79309c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import openai\n",
    "openai.api_base = \"\"\n",
    "openai.api_key = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a41a2dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = 'When was the Data Science term first coined?'\n",
    "Q2 = 'What are the main topics in Data Science?'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63d4c5f",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "\n",
    "TODO: In the cells below, load your chosen dataset into a `pandas` dataframe with a column named `\"text\"`. This column should contain all of your text data, separated into at least 20 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c69b83a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data science is an interdisciplinary academic field that uses statistics, scientific computing, scientific methods, processing, scientific visualization, algorithms and systems to extract or extrapolate knowledge and insights from potentially noisy, structured, or unstructured data. ',\n",
       " 'Data science also integrates domain knowledge from the underlying application domain (e.g., natural sciences, information technology, and medicine). Data science is multifaceted and can be described as a science, a research paradigm, a research method, a discipline, a workflow, and a profession.']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the Wikipedia page for \"Data Science\"\n",
    "params = {\n",
    "    \"action\": \"query\", \n",
    "    \"prop\": \"extracts\",\n",
    "    \"exlimit\": 1,\n",
    "    \"titles\": \"Data_science\",\n",
    "    \"explaintext\": 1,\n",
    "    \"formatversion\": 2,\n",
    "    \"format\": \"json\"\n",
    "}\n",
    "resp = requests.get(\"https://en.wikipedia.org/w/api.php\", params=params)\n",
    "response_dict = resp.json()\n",
    "#print first two paragraphs of loaded data (paragraphs identified by line breaks)\n",
    "response_dict[\"query\"][\"pages\"][0][\"extract\"].split(\"\\n\")[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a595980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load page text into a dataframe by adding each paragraph into a separate row. Later we'll create embeddings at the paragraph level. \n",
    "# Identify paragraphs by line breaks (\"\\n\")\n",
    "df = pd.DataFrame()\n",
    "df[\"text\"] = response_dict[\"query\"][\"pages\"][0][\"extract\"].split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dbb74a",
   "metadata": {},
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "acb3a9fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data science is an interdisciplinary academic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data science also integrates domain knowledge ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data science is \"a concept to unify statistics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A data scientist is a professional who creates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data science is an interdisciplinary field foc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Many statisticians, including Nate Silver, hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stanford professor David Donoho writes that da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>In 1962, John Tukey described a field he calle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The term \"data science\" has been traced back t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>During the 1990s, popular terms for the proces...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>In 2012, technologists Thomas H. Davenport and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The modern conception of data science as an in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The professional title of \"data scientist\" has...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>There is still no consensus on the definition ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Data science and data analysis are both import...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Data analysis typically involves working with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Data science, on the other hand, is a more com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>While data analysis focuses on extracting insi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Despite these differences, data science and da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>In summary, data analysis and data science are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>As illustrated in the previous sections, there...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Cloud computing can offer access to large amou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Some distributed computing frameworks are desi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Data science involve collecting, processing, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Machine learning models can amplify existing b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text\n",
       "0   Data science is an interdisciplinary academic ...\n",
       "1   Data science also integrates domain knowledge ...\n",
       "2   Data science is \"a concept to unify statistics...\n",
       "3   A data scientist is a professional who creates...\n",
       "4   Data science is an interdisciplinary field foc...\n",
       "5   Many statisticians, including Nate Silver, hav...\n",
       "6   Stanford professor David Donoho writes that da...\n",
       "7   In 1962, John Tukey described a field he calle...\n",
       "8   The term \"data science\" has been traced back t...\n",
       "9   During the 1990s, popular terms for the proces...\n",
       "10  In 2012, technologists Thomas H. Davenport and...\n",
       "11  The modern conception of data science as an in...\n",
       "12  The professional title of \"data scientist\" has...\n",
       "13  There is still no consensus on the definition ...\n",
       "14  Data science and data analysis are both import...\n",
       "15  Data analysis typically involves working with ...\n",
       "16  Data science, on the other hand, is a more com...\n",
       "17  While data analysis focuses on extracting insi...\n",
       "18  Despite these differences, data science and da...\n",
       "19  In summary, data analysis and data science are...\n",
       "20  As illustrated in the previous sections, there...\n",
       "21  Cloud computing can offer access to large amou...\n",
       "22  Some distributed computing frameworks are desi...\n",
       "23  Data science involve collecting, processing, a...\n",
       "24  Machine learning models can amplify existing b..."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# anything below the see also section in wikipedia is not useful for this use case\n",
    "index_to_cut = df[df['text'].str.contains('See also', na=False)].index.min()\n",
    "if not pd.isna(index_to_cut):\n",
    "    df = df.iloc[:index_to_cut]\n",
    "# Clean up text to remove empty lines and headings\n",
    "df = df[(df[\"text\"].str.len() > 0) & (~df[\"text\"].str.startswith(\"==\"))]\n",
    "df.reset_index(inplace = True, drop = True)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166fb16f",
   "metadata": {},
   "source": [
    "## Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e991c23c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>token_count</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data science is an interdisciplinary academic ...</td>\n",
       "      <td>45</td>\n",
       "      <td>[-0.01429750770330429, 0.006413985043764114, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  token_count  \\\n",
       "0  Data science is an interdisciplinary academic ...           45   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [-0.01429750770330429, 0.006413985043764114, 0...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "import pandas as pd\n",
    "import openai\n",
    "\n",
    "# Define model and tokenizer\n",
    "EMBEDDING_MODEL_NAME = \"text-embedding-ada-002\"\n",
    "TOKENIZER_ENCODING = \"cl100k_base\" \n",
    "# Create a tokenizer that is designed to align with our embeddings\n",
    "tokenizer = tiktoken.get_encoding(TOKENIZER_ENCODING)\n",
    "\n",
    "# Function to count tokens in a text\n",
    "def count_tokens(text):\n",
    "    return len(tokenizer.encode(text))\n",
    "\n",
    "# Add a column with token counts\n",
    "df['token_count'] = df['text'].apply(count_tokens)\n",
    "\n",
    "# Define token limit for a single batch\n",
    "BATCH_TOKEN_LIMIT = 8191\n",
    "\n",
    "# Initialize variables for batching\n",
    "current_batch = []\n",
    "current_tokens = 0\n",
    "embeddings = []\n",
    "\n",
    "# Iterate over rows to form batches dynamically\n",
    "for _, row in df.iterrows():\n",
    "    text = row['text']\n",
    "    tokens = row['token_count']\n",
    "\n",
    "    # Check if adding this text exceeds the token limit\n",
    "    if current_tokens + tokens > BATCH_TOKEN_LIMIT:\n",
    "        # Send current batch to the API\n",
    "        response = openai.Embedding.create(\n",
    "            input=current_batch,\n",
    "            engine=EMBEDDING_MODEL_NAME\n",
    "        )\n",
    "        embeddings.extend([data[\"embedding\"] for data in response[\"data\"]])\n",
    "\n",
    "        # Reset batch\n",
    "        current_batch = []\n",
    "        current_tokens = 0\n",
    "\n",
    "    # Add the current text to the batch\n",
    "    current_batch.append(text)\n",
    "    current_tokens += tokens\n",
    "\n",
    "# Process the last batch if any\n",
    "if current_batch:\n",
    "    response = openai.Embedding.create(\n",
    "        input=current_batch,\n",
    "        engine=EMBEDDING_MODEL_NAME\n",
    "    )\n",
    "    embeddings.extend([data[\"embedding\"] for data in response[\"data\"]])\n",
    "\n",
    "# Add embeddings to the DataFrame\n",
    "df[\"embeddings\"] = embeddings\n",
    "\n",
    "# Display the DataFrame\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1189f2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"embeddings_wiki_ds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "557075ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  embeddings_wiki_ds.csv  project.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c081cd",
   "metadata": {},
   "source": [
    "To stop the notebook here and come back, you can reload `df` using this code (adding your API key) rather than generating the embeddings again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5f4f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import openai\n",
    "# openai.api_base = \"https://openai.vocareum.com/v1\"\n",
    "# openai.api_key = \"YOUR API KEY\"\n",
    "# df = pd.read_csv(\"embeddings.csv\", index_col=0)\n",
    "# df[\"embeddings\"] = df[\"embeddings\"].apply(eval).apply(np.array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae769871",
   "metadata": {},
   "source": [
    "## RAG-based Custom Query Completion\n",
    "\n",
    "TODO: In the cells below, compose a custom query using your chosen dataset and retrieve results from an OpenAI `Completion` model. You may copy and paste any useful code from the course materials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5278a1",
   "metadata": {},
   "source": [
    "### Retrieval pipeline (semantic search) - Create a Function that Finds Related Pieces of Text for a Given Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2efb1fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.embeddings_utils import get_embedding, distances_from_embeddings\n",
    "\n",
    "def get_rows_sorted_by_relevance(question_embeddings, df):\n",
    "    \"\"\"\n",
    "    Function that takes in a question string and a dataframe containing\n",
    "    rows of text and associated embeddings, and returns that dataframe\n",
    "    sorted from least to most relevant for that question\n",
    "    \"\"\"\n",
    "    \n",
    "    # Make a copy of the dataframe and add a \"distances\" column containing\n",
    "    # the cosine distances between each row's embeddings and the\n",
    "    # embeddings of the question\n",
    "    df_copy = df.copy()\n",
    "    df_copy[\"distances\"] = distances_from_embeddings(\n",
    "        question_embeddings,\n",
    "        df_copy[\"embeddings\"].values,\n",
    "        distance_metric=\"cosine\"\n",
    "    )\n",
    "    \n",
    "    # Sort the copied dataframe by the distances and return it\n",
    "    # (shorter distance = more relevant so we sort in ascending order)\n",
    "    df_copy.sort_values(\"distances\", ascending=True, inplace=True)\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "75bc0b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get embeddings for the question text\n",
    "Q1_embedding = get_embedding(Q1, engine=EMBEDDING_MODEL_NAME)\n",
    "Q2_embedding = get_embedding(Q2, engine=EMBEDDING_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e264d8d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>token_count</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>distances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The term \"data science\" has been traced back t...</td>\n",
       "      <td>156</td>\n",
       "      <td>[-0.00794466957449913, -0.006920174229890108, ...</td>\n",
       "      <td>0.113138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The modern conception of data science as an in...</td>\n",
       "      <td>138</td>\n",
       "      <td>[-0.014102050103247166, 0.007750300690531731, ...</td>\n",
       "      <td>0.123728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>In 1962, John Tukey described a field he calle...</td>\n",
       "      <td>113</td>\n",
       "      <td>[-0.012454736977815628, 0.0004028491675853729,...</td>\n",
       "      <td>0.129511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The professional title of \"data scientist\" has...</td>\n",
       "      <td>74</td>\n",
       "      <td>[-0.030461788177490234, -0.002075143391266465,...</td>\n",
       "      <td>0.148623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>During the 1990s, popular terms for the proces...</td>\n",
       "      <td>33</td>\n",
       "      <td>[-0.02157468907535076, -0.0010463348589837551,...</td>\n",
       "      <td>0.149730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  token_count  \\\n",
       "8   The term \"data science\" has been traced back t...          156   \n",
       "11  The modern conception of data science as an in...          138   \n",
       "7   In 1962, John Tukey described a field he calle...          113   \n",
       "12  The professional title of \"data scientist\" has...           74   \n",
       "9   During the 1990s, popular terms for the proces...           33   \n",
       "\n",
       "                                           embeddings  distances  \n",
       "8   [-0.00794466957449913, -0.006920174229890108, ...   0.113138  \n",
       "11  [-0.014102050103247166, 0.007750300690531731, ...   0.123728  \n",
       "7   [-0.012454736977815628, 0.0004028491675853729,...   0.129511  \n",
       "12  [-0.030461788177490234, -0.002075143391266465,...   0.148623  \n",
       "9   [-0.02157468907535076, -0.0010463348589837551,...   0.149730  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_q1_similarity_sorted = get_rows_sorted_by_relevance(Q1_embedding, df)\n",
    "df_q1_similarity_sorted.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "582f0656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>token_count</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>distances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data science is an interdisciplinary academic ...</td>\n",
       "      <td>45</td>\n",
       "      <td>[-0.01429750770330429, 0.006413985043764114, 0...</td>\n",
       "      <td>0.145862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data science is an interdisciplinary field foc...</td>\n",
       "      <td>178</td>\n",
       "      <td>[-0.01713685691356659, 0.0032929459121078253, ...</td>\n",
       "      <td>0.159820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Data science involve collecting, processing, a...</td>\n",
       "      <td>35</td>\n",
       "      <td>[-0.012967286631464958, -0.0069978199899196625...</td>\n",
       "      <td>0.160908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Data science, on the other hand, is a more com...</td>\n",
       "      <td>117</td>\n",
       "      <td>[-0.011719823814928532, 0.004833708051592112, ...</td>\n",
       "      <td>0.165301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>In summary, data analysis and data science are...</td>\n",
       "      <td>90</td>\n",
       "      <td>[-0.01534644141793251, 0.006740248762071133, 0...</td>\n",
       "      <td>0.166335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  token_count  \\\n",
       "0   Data science is an interdisciplinary academic ...           45   \n",
       "4   Data science is an interdisciplinary field foc...          178   \n",
       "23  Data science involve collecting, processing, a...           35   \n",
       "16  Data science, on the other hand, is a more com...          117   \n",
       "19  In summary, data analysis and data science are...           90   \n",
       "\n",
       "                                           embeddings  distances  \n",
       "0   [-0.01429750770330429, 0.006413985043764114, 0...   0.145862  \n",
       "4   [-0.01713685691356659, 0.0032929459121078253, ...   0.159820  \n",
       "23  [-0.012967286631464958, -0.0069978199899196625...   0.160908  \n",
       "16  [-0.011719823814928532, 0.004833708051592112, ...   0.165301  \n",
       "19  [-0.01534644141793251, 0.006740248762071133, 0...   0.166335  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_q2_similarity_sorted = get_rows_sorted_by_relevance(Q2_embedding, df)\n",
    "df_q2_similarity_sorted.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "93b847c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2110"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total token in document\n",
    "df.token_count.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d069dd30",
   "metadata": {},
   "source": [
    "### Augmentation pipeline - Create a Function that Composes a Text Prompt with Retrieved Text Augmented"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962cd987",
   "metadata": {},
   "source": [
    "Building on that sorted list of rows, we're going to select the create a text prompt that provides context to a `Completion` model in order to help it answer a question. The outline of the prompt looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdb4d28",
   "metadata": {},
   "source": [
    "```\n",
    "Answer the question based on the context below, and if the\n",
    "question can't be answered based on the context, say \"I don't\n",
    "know\"\n",
    "\n",
    "Context:\n",
    "\n",
    "{context}\n",
    "\n",
    "---\n",
    "\n",
    "Question: {question}\n",
    "Answer:\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab54a64a",
   "metadata": {},
   "source": [
    "Normally, we want to fit as much of our dataset as possible into the \"context\" part of the prompt without exceeding the number of tokens allowed by the `Completion` model, which is currently 4,000.\n",
    "\n",
    "Since the total token counts in our document is 2,000 we'll limit the token count inserted to 500, to ensure we are testing whether our retrieval strategy is effect.\n",
    "\n",
    "We'll loop over the dataset, counting the tokens as we go, and stop when we hit the limit. Then we'll join that list of text data into a single string and add it to the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b4183f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def create_prompt(question, question_embedding, df, max_token_count):\n",
    "    \"\"\"\n",
    "    Given a question and a dataframe containing rows of text and their\n",
    "    embeddings, return a text prompt to send to a Completion model\n",
    "    \"\"\"\n",
    "    # Create a tokenizer that is designed to align with our embeddings\n",
    "    tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    \n",
    "    # Count the number of tokens in the prompt template and question\n",
    "    prompt_template = \"\"\"\n",
    "Answer the question based on the context below, and if the question\n",
    "can't be answered based on the context, say \"I don't know\"\n",
    "\n",
    "Context: \n",
    "\n",
    "{}\n",
    "\n",
    "---\n",
    "\n",
    "Question: {}\n",
    "Answer:\"\"\"\n",
    "    \n",
    "    current_token_count = len(tokenizer.encode(prompt_template)) + \\\n",
    "                            len(tokenizer.encode(question))\n",
    "    \n",
    "    #context will be made up from the retrieved text by similarity until max_token_count is reached\n",
    "    context = []\n",
    "    for text in get_rows_sorted_by_relevance(question_embedding, df)[\"text\"].values:\n",
    "        \n",
    "        # Increase the counter based on the number of tokens in this row\n",
    "        text_token_count = len(tokenizer.encode(text))\n",
    "        current_token_count += text_token_count\n",
    "        \n",
    "        # Add the row of text to the list if we haven't exceeded the max\n",
    "        if current_token_count <= max_token_count:\n",
    "            context.append(text)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return prompt_template.format(\"\\n\\n###\\n\\n\".join(context), question)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022e1680",
   "metadata": {},
   "source": [
    "test augmented prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "75acce3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer the question based on the context below, and if the question\n",
      "can't be answered based on the context, say \"I don't know\"\n",
      "\n",
      "Context: \n",
      "\n",
      "The term \"data science\" has been traced back to 1974, when Peter Naur proposed it as an alternative name to computer science. In 1996, the International Federation of Classification Societies became the first conference to specifically feature data science as a topic. However, the definition was still in flux. After the 1985 lecture at the Chinese Academy of Sciences in Beijing, in 1997 C. F. Jeff Wu again suggested that statistics should be renamed data science. He reasoned that a new name would help statistics shed inaccurate stereotypes, such as being synonymous with accounting or limited to describing data. In 1998, Hayashi Chikio argued for data science as a new, interdisciplinary concept, with three aspects: data design, collection, and analysis.\n",
      "\n",
      "###\n",
      "\n",
      "The modern conception of data science as an independent discipline is sometimes attributed to William S. Cleveland. In a 2001 paper, he advocated an expansion of statistics beyond theory into technical areas; because this would significantly change the field, it warranted a new name. \"Data science\" became more widely used in the next few years: in 2002, the Committee on Data for Science and Technology launched the Data Science Journal. In 2003, Columbia University launched The Journal of Data Science. In 2014, the American Statistical Association's Section on Statistical Learning and Data Mining changed its name to the Section on Statistical Learning and Data Science, reflecting the ascendant popularity of data science.\n",
      "\n",
      "###\n",
      "\n",
      "In 1962, John Tukey described a field he called \"data analysis\", which resembles modern data science. In 1985, in a lecture given to the Chinese Academy of Sciences in Beijing, C. F. Jeff Wu used the term \"data science\" for the first time as an alternative name for statistics. Later, attendees at a 1992 statistics symposium at the University of Montpellier  II acknowledged the emergence of a new discipline focused on data of various origins and forms, combining established concepts and principles of statistics and data analysis with computing.\n",
      "\n",
      "---\n",
      "\n",
      "Question: When was the Data Science term first coined?\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "print(create_prompt(Q1, Q1_embedding, df, max_token_count = 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "418f18b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer the question based on the context below, and if the question\n",
      "can't be answered based on the context, say \"I don't know\"\n",
      "\n",
      "Context: \n",
      "\n",
      "Data science is an interdisciplinary academic field that uses statistics, scientific computing, scientific methods, processing, scientific visualization, algorithms and systems to extract or extrapolate knowledge and insights from potentially noisy, structured, or unstructured data. \n",
      "\n",
      "###\n",
      "\n",
      "Data science is an interdisciplinary field focused on extracting knowledge from typically large data sets and applying the knowledge and insights from that data to solve problems in a wide range of application domains. The field encompasses preparing data for analysis, formulating data science problems, analyzing data, developing data-driven solutions, and presenting findings to inform high-level decisions in a broad range of application domains. As such, it incorporates skills from computer science, statistics, information science, mathematics, data visualization, information visualization, data sonification, data integration, graphic design, complex systems, communication and business. Statistician Nathan Yau, drawing on Ben Fry, also links data science to human–computer interaction: users should be able to intuitively control and explore data. In 2015, the American Statistical Association identified database management, statistics and machine learning, and distributed and parallel systems as the three emerging foundational professional communities.\n",
      "\n",
      "###\n",
      "\n",
      "Data science involve collecting, processing, and analyzing data which often including personal and sensitive information. Ethical concerns include potential privacy violations, bias perpetuation, and negative societal impacts \n",
      "\n",
      "###\n",
      "\n",
      "Data science, on the other hand, is a more complex and iterative process that involves working with larger, more complex datasets that often require advanced computational and statistical methods to analyze. Data scientists often work with unstructured data such as text or images and use machine learning algorithms to build predictive models and make data-driven decisions. In addition to statistical analysis, data science often involves tasks such as data preprocessing, feature engineering, and model selection. For instance, a data scientist might develop a recommendation system for an e-commerce platform by analyzing user behavior patterns and using machine learning algorithms to predict user preferences.\n",
      "\n",
      "---\n",
      "\n",
      "Question: What are the main topics in Data Science?\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "print(create_prompt(Q2, Q2_embedding, df, max_token_count = 500))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c6fd64",
   "metadata": {},
   "source": [
    "### Generation pipeline - Create a Function that Answers a Question Using the Prompt (with the augmented text) Created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "edb27649",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETION_MODEL_NAME = \"gpt-3.5-turbo-instruct\"\n",
    "\n",
    "def answer_question_with_RAG(\n",
    "    question, question_embedding, df, max_prompt_tokens=500, max_answer_tokens=150\n",
    "):\n",
    "    \"\"\"\n",
    "    Given a question, a dataframe containing rows of text, and a maximum\n",
    "    number of desired tokens in the prompt and response, return the\n",
    "    answer to the question according to an OpenAI Completion model\n",
    "    \n",
    "    If the model produces an error, return an empty string\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = create_prompt(question, question_embedding, df, max_prompt_tokens)\n",
    "    \n",
    "    try:\n",
    "        response = openai.Completion.create(\n",
    "            model=COMPLETION_MODEL_NAME,\n",
    "            prompt=prompt,\n",
    "            max_tokens=max_answer_tokens\n",
    "        )\n",
    "        return response[\"choices\"][0][\"text\"].strip()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return \"\"\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1783f146",
   "metadata": {},
   "source": [
    "## Custom Performance Demonstration\n",
    "\n",
    "TODO: In the cells below, demonstrate the performance of your custom query using at least 2 questions. For each question, show the answer from a basic `Completion` model query as well as the answer from your custom query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f11fdc0",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "831147c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The term \"data science\" was first coined in 2001 by William S. Cleveland, a statistician and professor at Purdue University.\n"
     ]
    }
   ],
   "source": [
    "Q1_initial_prompt = f\"\"\"\n",
    "Question: {Q1}\n",
    "Answer:\n",
    "\"\"\"\n",
    "initial_Q1_answer = openai.Completion.create(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    prompt=Q1_initial_prompt,\n",
    "    max_tokens=150\n",
    ")[\"choices\"][0][\"text\"].strip()\n",
    "print(initial_Q1_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "eefd8db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1974, when Peter Naur proposed it as an alternative name to computer science.\n"
     ]
    }
   ],
   "source": [
    "RAG_based_Q1_answer = answer_question_with_RAG(Q1, Q1_embedding, df)\n",
    "print(RAG_based_Q1_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4901c850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "When was the Data Science term first coined? \n",
      "\n",
      "Original Answer: \n",
      " The term \"data science\" was first coined in 2001 by William S. Cleveland, a statistician and professor at Purdue University.  \n",
      "\n",
      "RAG-Based Answer:   \n",
      " 1974, when Peter Naur proposed it as an alternative name to computer science.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "{Q1} \\n\n",
    "Original Answer: \\n {initial_Q1_answer}  \\n\n",
    "RAG-Based Answer:   \\n {RAG_based_Q1_answer}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e86e37c",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6f646989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Data Analysis: This topic involves understanding how to collect, clean, and transform data in order to extract useful insights and patterns.\n",
      "\n",
      "2. Data Visualization: Data science also involves using visual tools such as charts, graphs, and maps to communicate the information and insights gained from data analysis.\n",
      "\n",
      "3. Machine Learning: This topic focuses on building and training algorithms that can automatically learn from data and make predictions or decisions without explicit programming.\n",
      "\n",
      "4. Natural Language Processing: This is a subfield of data science that deals with understanding and analyzing human language, both written and spoken.\n",
      "\n",
      "5. Data Mining: This involves discovering patterns and relationships within large datasets using various statistical and computational methods.\n",
      "\n",
      "6. Predictive Modeling: This topic involves using statistical and machine learning techniques\n"
     ]
    }
   ],
   "source": [
    "Q2_initial_prompt = f\"\"\"\n",
    "Question: {Q2}\n",
    "Answer:\n",
    "\"\"\"\n",
    "initial_Q2_answer = openai.Completion.create(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    prompt=Q2_initial_prompt,\n",
    "    max_tokens=150\n",
    ")[\"choices\"][0][\"text\"].strip()\n",
    "print(initial_Q2_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "11c07a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main topics in Data Science are statistics, scientific computing, scientific methods, processing, scientific visualization, algorithms, systems, data integration, graphic design, complex systems, communication, business, human-computer interaction, database management, machine learning, and distributed/parallel systems.\n"
     ]
    }
   ],
   "source": [
    "RAG_based_Q2_answer = answer_question_with_RAG(Q2, Q2_embedding, df)\n",
    "print(RAG_based_Q2_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0fdb59c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "What are the main topics in Data Science? \n",
      "\n",
      "Original Answer: \n",
      " 1. Data Analysis: This topic involves understanding how to collect, clean, and transform data in order to extract useful insights and patterns.\n",
      "\n",
      "2. Data Visualization: Data science also involves using visual tools such as charts, graphs, and maps to communicate the information and insights gained from data analysis.\n",
      "\n",
      "3. Machine Learning: This topic focuses on building and training algorithms that can automatically learn from data and make predictions or decisions without explicit programming.\n",
      "\n",
      "4. Natural Language Processing: This is a subfield of data science that deals with understanding and analyzing human language, both written and spoken.\n",
      "\n",
      "5. Data Mining: This involves discovering patterns and relationships within large datasets using various statistical and computational methods.\n",
      "\n",
      "6. Predictive Modeling: This topic involves using statistical and machine learning techniques  \n",
      "\n",
      "RAG-Based Answer:   \n",
      " The main topics in Data Science are statistics, scientific computing, scientific methods, processing, scientific visualization, algorithms, systems, data integration, graphic design, complex systems, communication, business, human-computer interaction, database management, machine learning, and distributed/parallel systems.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "{Q2} \\n\n",
    "Original Answer: \\n {initial_Q2_answer}  \\n\n",
    "RAG-Based Answer:   \\n {RAG_based_Q2_answer}\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
